---
title: "Projekt - część opisowa"
author: "Mateusz Surowiec"
date: "2025-04-27"
output:  
   html_document:
    code_folding: show
---

### Część Opisowa

# Wczytanie danych i pakietów

```{r setup, include=FALSE}
library(dplyr)
library(readxl)
library(e1071)
library(openxlsx)
library(ggplot2)
library(gridExtra)
library(scorecard)
library(purrr)
library(bigstatsr)
library(tidyr)
library(progress)

Dane_projekt <- read_excel("~/Desktop/szkola/AG_magisterka/semestr 4/modele_scoringowe/kredyty_auto_Scoring2025s.xlsx")
# View(Dane_projekt)

knitr::opts_chunk$set(echo = TRUE)
```

# Sprawdzenie danych

```{r}
str(Dane_projekt)
sapply(Dane_projekt, class)

# Zmienne:
# data_akceptacji - data
# grupa_ryzyka - kategoria
# kod_partnera - kategoria
# typ_umowy - kategoria („N” – nowy samochód, „U” – samochód używany, „R” – refinansowanie kredytu)
# scoring_FICO - liczba
# okres_kredytu - liczba (miesiące)
# kwota_kredytu - liczba
# oproc.refin - liczba (dla typu umowy „R”)
# oproc_konkur - liczba
# koszt_pieniadza - liczba
# oproc_propon - liczba
# akceptacja_klienta - kategoria (zmienna celu ->  0 = brak akceptacji, 1 = akceptacja )

# Sprawdzenie braków
sum(is.na(Dane_projekt))
# nie ma braków

```

# Statystyki opisowe - dla ilościowych

```{r}
zm_ilosciowe <- c("scoring_FICO", "kwota_kredytu", "oproc_konkur", "koszt_pieniadza", "oproc_propon")

oprocentowanie_refin <- Dane_projekt[Dane_projekt$typ_umowy == "R", ] # osobno, tylko dla typu umowy "R"

# Funkcja do obliczenia statystyk
calculate_stats <- function(data, var_name) {
  stats <- c(
    Mean = mean(data[[var_name]], na.rm = TRUE),
    Median = median(data[[var_name]], na.rm = TRUE),
    Max = max(data[[var_name]], na.rm = TRUE),
    Min = min(data[[var_name]], na.rm = TRUE),
    SD = sd(data[[var_name]], na.rm = TRUE),
    Range = diff(range(data[[var_name]], na.rm = TRUE)),
    Skewness = skewness(data[[var_name]], na.rm = TRUE),
    Kurtosis = kurtosis(data[[var_name]], na.rm = TRUE),
    IQR = IQR(data[[var_name]], na.rm = TRUE)
  )
  return(stats)
}

# Obliczenia dla zmiennych ilościowych
stats_table <- sapply(zm_ilosciowe, function(var) calculate_stats(Dane_projekt, var))
# Dla zmiennej 'oprocentowanie.refin'
stats_table_refin <- sapply("oproc_refin", function(var) calculate_stats(oprocentowanie_refin, var))

# Połączenie wyników
final_stats <- cbind(stats_table, stats_table_refin)
final_stats <- t(final_stats)

options(scipen = 999)
print(final_stats)
write.xlsx(final_stats, file = "Wyniki.xlsx", sheetName = "stat_opis_il", rowNames = TRUE)
```

```{r}
# Ustaw układ wykresów 3/3/1
par(mfrow = c(3, 3))

# Rysowanie wykresów
for (zm in zm_ilosciowe) {
  hist(Dane_projekt[[zm]],
       main = paste("Histogram:", zm),
       xlab = "",   
       col = "lightblue",
       border = "black")
}

hist(oprocentowanie_refin$oproc_refin,
     main = "Histogram: oproc_refin",
     xlab = "",
     col = "lightblue",
     border = "black")
```



# Tabele liczebności - dla kategorycznych

```{r}

zm_kategotyczne <- c("grupa_ryzyka", "kod_partnera", "okres_kredytu", "typ_umowy", "akceptacja_klienta")

for (var in zm_kategotyczne) {

  cat_table <- table(Dane_projekt[[var]], useNA = "ifany")
  cat_prop <- prop.table(cat_table)  # Częstości (proporcje)
  cat_df <- data.frame(
    Category = names(cat_table),
    Count = as.vector(cat_table),
    Proportion = as.vector(cat_prop)
  )
  cat("Tabela dla zmiennej:", var, "\n")
  print(cat_df)
  cat("\n")
}
```

# Histogramy dla kategorycznych

```{r}
# grupa_ryzyka
plot1 <- ggplot(Dane_projekt, aes(x = grupa_ryzyka)) +
  geom_histogram(stat = "count", fill = "skyblue", color = "black") +
  labs(title = "Histogram dla grupy ryzyka",
       y = "Liczba obserwacji") + theme_minimal()+
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(hjust = 1, size = 12), 
    axis.text.y = element_text(size = 10))  

# kod_partnera
plot2 <- ggplot(Dane_projekt, aes(x = kod_partnera)) +
  geom_histogram(stat = "count", fill = "yellow", color = "black") +
  labs(title = "Histogram dla kodu partnera",
        y = "Liczba obserwacji") + theme_minimal()+
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(hjust = 1, size = 12), 
    axis.text.y = element_text(size = 10))  

# typ_umowy
plot3 <- ggplot(Dane_projekt, aes(x = typ_umowy)) +
  geom_histogram(stat = "count", fill = "green", color = "black") +
  labs(title = "Histogram dla typu umowy",
        y = "Liczba obserwacji") + theme_minimal()+
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(hjust = 1, size = 12),  
    axis.text.y = element_text(size = 10))  

# okres_kredytu
plot4 <- ggplot(Dane_projekt, aes(x = factor(okres_kredytu))) +
  geom_bar(fill = "orange", color = "black") +
  labs(title = "Histogram dla akceptacji klienta",
        y = "Liczba obserwacji") + 
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(hjust = 1, size = 12), 
    axis.text.y = element_text(size = 10)  
  )

# akceptacja_klienta
plot5 <- ggplot(Dane_projekt, aes(x = factor(akceptacja_klienta))) +
  geom_bar(fill = "red", color = "black") +
  labs(title = "Histogram dla akceptacji klienta",
        y = "Liczba obserwacji") + 
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(hjust = 1, size = 12), 
    axis.text.y = element_text(size = 10)  
  )

grid.arrange(plot1, plot2, plot3, plot4, ncol = 2, nrow = 2)

print(plot5)
```



# Część Michała:


# Załadowanie danych z utworzonymi zmiennymi pochodnymi oraz potrzebnych bibliotek. Kod tworzący zmienne pochodne został wykonany w pythonie i dodany będzie w osobnym pliku.
```{r}
library(Information)
library(scorecard)
library(pROC)
library(dplyr)
library(readxl)

#project_data <- read.csv("C:/Users/mateu/Desktop/Semestr IV/Modele scoringowe/Projekt/project_data.csv")
project_data <- read.csv("~/Desktop/szkola/AG_magisterka/semestr 4/modele_scoringowe/project_data.csv")
# project_data <- read.csv("C:/Users/micha/Downloads/project_data.csv")
 
project_data$kod_partnera <- as.factor(project_data$kod_partnera)
project_data$grupa_ryzyka <- as.factor(project_data$grupa_ryzyka)

exclude_cols <- c("LP", "data_akceptacji"
 , "kwota_kredytu", "oproc_refin", 
                 "oproc_konkur", "koszt_pieniadza", "oproc_propon", 
                  "umowa_N", "koszt_propon", "koszt_konkur")

vars_to_analyze <- setdiff(names(project_data), c(exclude_cols, "akceptacja_klienta"))
```


# Wstępna analiza IV, bins odgórnie ustalone na 10
```{r}

# Przygotowanie danych do analizy IV
iv_data <- project_data[, c(vars_to_analyze, "akceptacja_klienta")]

# Upewnienie się, że zmienna celu jest typu numeric (zgodnie z błędem)
iv_data$akceptacja_klienta <- as.numeric(as.character(iv_data$akceptacja_klienta))

# Zdefiniowanie bad 
iv_data$bad <- ifelse(iv_data$akceptacja_klienta == 1, 0, 1)

# Sprawdzenie, czy zmienna celu ma wartości 0 i 1
cat("Unikalne wartości zmiennej bad:", unique(iv_data$bad), "\n")

# Obliczenie IV dla wszystkich zmiennych za pomocą funkcji create_infotables
# Ta funkcja automatycznie obliczy IV dla wszystkich zmiennych w zbiorze danych
iv_results <- Information::create_infotables(data = iv_data, 
                                             y = "bad", 
                                             bins = 10,
                                             parallel = FALSE)

# Wyodrębnienie wyników IV
iv_values <- iv_results$Summary

# Sortowanie wartości IV w kolejności malejącej
iv_values <- iv_values[order(-iv_values$IV), ]

# Wyświetlenie wyników
cat("\n=== Wartości IV dla zmiennych (posortowane) ===\n")
for (i in 1:nrow(iv_values)) {
  cat(sprintf("%s: %.4f\n", iv_values$Variable[i], iv_values$IV[i]))
}

```



# Próbujemy poprawić IV poprzez iteracyjne dobranie najlepszej wartość binsów dla każdej ze zmiennych
```{r}
# Przygotowanie danych do analizy IV
# Tutaj pomijamy już zmienną akceptacja klienta
iv_data <- iv_data[, c(vars_to_analyze, "bad")]

# Upewnienie się, że zmienna celu jest typu numeric
iv_data$bad <- as.numeric(as.character(iv_data$bad))

# Sprawdzenie, czy zmienna celu ma wartości 0 i 1
cat("Unikalne wartości zmiennej bad:", unique(iv_data$bad), "\n")

# Funkcja do znalezienia optymalnej liczby bins dla każdej zmiennej
find_optimal_bins <- function(data, variable, target, max_bins = 20) {
  best_iv <- -Inf
  best_bins <- 10
  for (bins in 2:max_bins) {
    iv_result <- Information::create_infotables(data = data[, c(variable, target)], 
                                                y = target, 
                                                bins = bins, 
                                                parallel = FALSE)
    iv_value <- iv_result$Summary$IV[1]
    if (iv_value > best_iv) {
      best_iv <- iv_value
      best_bins <- bins
    }
  }
  return(list(best_bins = best_bins, best_iv = best_iv))
}

# Obliczenie optymalnych bins dla każdej zmiennej
optimal_bins <- list()
for (var in vars_to_analyze) {
  result <- find_optimal_bins(iv_data, var, "bad")
  optimal_bins[[var]] <- result
  cat(sprintf("Zmienna: %s, Optymalne bins: %d, IV: %.4f\n", var, result$best_bins, result$best_iv))
}

# Obliczenie IV z optymalnymi bins
iv_results <- lapply(vars_to_analyze, function(var) {
  bins <- optimal_bins[[var]]$best_bins
  Information::create_infotables(data = iv_data[, c(var, "bad")], 
                                 y = "bad", 
                                 bins = bins, 
                                 parallel = FALSE)
})

# Wyodrębnienie wyników IV
iv_values <- do.call(rbind, lapply(iv_results, function(res) res$Summary))
iv_values <- iv_values[order(-iv_values$IV), ]

# Wyświetlenie wyników
cat("\n=== Wartości IV dla zmiennych (posortowane) ===\n")
for (i in 1:nrow(iv_values)) {
  cat(sprintf("%s: %.4f\n", iv_values$Variable[i], iv_values$IV[i]))
}
```
#Tworzymy elegancką tabelę dla wartości IV i optymalnej liczby binsów

```{r}
# Konwersja optimal_bins na data frame
optimal_bins_df <- do.call(rbind, lapply(names(optimal_bins), function(var) {
  data.frame(Variable = var, 
             Optimal_Bins = optimal_bins[[var]]$best_bins, 
             IV = optimal_bins[[var]]$best_iv)
}))

# Wyświetlenie wyników
optimal_bins_df <- optimal_bins_df[order(-optimal_bins_df$IV), ]
print(optimal_bins_df)


```


# Wykres IV i liczby koszyków dla danej zmiennej
```{r}
# Załadowanie biblioteki ggplot2
library(ggplot2)

# Utworzenie wykresu kolumnowego
wykres <- ggplot(optimal_bins_df, aes(x = reorder(Variable, -IV), y = IV, fill = as.factor(Optimal_Bins))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Wartości IV dla zmiennych i liczba optymalnych bins",
       x = "Zmienna",
       y = "Information Value (IV)",
       fill = "Liczba bins") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(wykres)
```



# C.D. - Mat

# a) Przyjęte zasady kubełkowania (ang. binning)
# Opis wyboru binsów zostawiam Michowi - on to liczył

# b) Wybrane zmienne (przyjęte metody i zasady preselekcji zmiennych, wynik preselekcji, 
# na tym etapie mogą również pojawić się nowe zmienne pochodne)

# Kryteria IV ze slajdu:
# < 0.02 - Uesless
# 0.02 - 0.1 - Weak
# 0.1 - 0.3 - Medium
# 0.3 - 0.5 - Strong
# 0.5 - 1.0 - Suspicious
# Zgodnie z treścią, powinniśmy uwzględniać tylko zmienne o IV na poziomie Medium/Strong


```{r}
# Wybieramy tylko te zmienne z IV na optymalnym poziomie
selected_vars <- optimal_bins_df %>%
  filter(IV > 0.1 & IV < 0.5) %>%
  pull(Variable)

# Stworzenie nowego DF z wybranymi zmiennymi
iv_data_selected <- iv_data %>%
  select(all_of(selected_vars), bad)

print(iv_data_selected)

```




```{r}
# Dane muszą być w odpowiedniej postaci
# wymagana jest lista binow do scorecarda
# Roboczo sobie na nowo zbinuje dane i przekształcę je do WOE
# Tutaj zastosowałem domyślną metodę "tree"

#Tworzymy scorecarda na podstawie najlepszego modelu, najlepszy okazał się model ze wszystkimi zmiennymi
bins <- woebin(iv_data, "bad", method = "tree")

iv_data_woe <-woebin_ply(iv_data, bins)

# Wyznaczenie IV
iv_table <- iv(iv_data_woe, y = "bad")
```



```{r}

# Tabela IV (zawiera więcej kolumn — wybieramy tylko potrzebne)
iv_table <- iv(iv_data_woe, y = "bad") %>%
  select(variable, info_value)

# Liczba unikalnych wartości (binów) po WOE
bin_counts <- iv_data_woe %>%
  select(-bad) %>%
  summarise(across(everything(), n_distinct)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "bins_count")

# Połączenie IV z liczbą binów
iv_table <- left_join(iv_table, bin_counts, by = "variable")

# Wykres
wykres <- ggplot(iv_table, aes(x = reorder(variable, -info_value), y = info_value, fill = as.factor(bins_count))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Wartości IV dla zmiennych i liczba wyznaczonych bins",
       x = "Zmienna",
       y = "Information Value (IV)",
       fill = "Liczba bins") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(wykres)
```



```{r}
# Filtrowanie zmiennych z IV > 0.1 i < 0.5
iv_selected <- subset(iv_table, info_value > 0.1 & info_value < 0.5)

# Pobranie nazw zmiennych spełniających kryteria
selected_vars <- as.character(iv_selected$variable)

# Weryfikacja: tylko zmienne, które faktycznie istnieją w danych
selected_vars <- selected_vars[selected_vars %in% colnames(iv_data_woe)]

# Dołączenie zmiennej celu do zbioru danych
vars_to_select <- c("bad", selected_vars)

# Wybór kolumn (ze wzg na składnię data.table — używamy ..)
iv_data_selected <- iv_data_woe[, ..vars_to_select]

#Konwersja do data.frame, żeby glm ogarnął
iv_data_selected_df <- as.data.frame(iv_data_selected)
```


```{r}
# Model
reg <- glm(bad ~ ., data = iv_data_selected_df, family = "binomial")
summary(reg)

# Wyznaczenie punktacji
card_final <- scorecard(bins, reg)

# Utworzenie NIEZBINOWANEGO zbioru danych na którym tworzymy scoring
# Usunięcie '_woe' z nazw zmiennych (poza zmienną celu)
vars_to_select_not_woe <- gsub("_woe$", "", vars_to_select[vars_to_select != "bad"])

# Dodanie zmiennej celu z powrotem na początek
vars_to_select_not_woe <- c("bad", vars_to_select_not_woe)

# Wybór zmiennych z niezbinowanego zbioru
iv_data_not_woe <- iv_data[, vars_to_select_not_woe]


# Wyznaczenie AUC i Gini
auc <- bigstatsr::AUC(-scorecard_ply(iv_data_not_woe, card_final)$score, iv_data_not_woe$bad)
gini <- 2 * auc - 1
#2*bigstatsr::AUC(-scorecard_ply(iv_data_selected, card_1)$score, iv_data_selected$bad)-1
auc
gini

```



```{r}
library(data.table)
library(officer)
library(flextable)

# Łączymy wszystkie data.table z card_final w jedną tabelę
card_final_df <- rbindlist(card_final,fill=TRUE)


# Wybieramy interesujace nas kolumny i sortujemy
card_final_df <- card_final_df[, .(variable, bin, points, count)]
setorder(card_final_df, variable, bin)

# Tworzymy flextable i scalamy komórki w kolumnie 'variable' posiadające tą samą wartość
ft <- flextable(card_final_df) %>%
  merge_v(j = "variable") %>%     # <- SCALANIE komórek w kolumnie 'variable'
  valign(j = "variable", valign = "top") %>%  # estetyka
  autofit()

# Eksportujemy do worda
doc <- read_docx()
doc <- body_add_par(doc, "Scorecard Table", style = "heading 1")
doc <- body_add_flextable(doc, ft)
print(doc, target = "scorecard_merged.docx")


```


```{r}

# Obliczanie score'u dla każdego rekordu
scored_data <- scorecard_ply(iv_data_not_woe, card_final)

# Dołączenie kolumny ze scoringiem
iv_data_with_scores_all <- cbind(iv_data_not_woe, scored_data)
iv_data_with_scores_all

summary(iv_data_with_scores_all$score)

```

```{r}
library(dplyr)

breaks_seq <- seq(floor(min(iv_data_with_scores_all$score)), ceiling(max(iv_data_with_scores_all$score)) + 24, by = 50)


# Tworzenie przedziałów co 20 punktów
iv_data_with_scores_all %>%
  mutate(score_bin = cut(score, breaks = breaks_seq, right = FALSE)) %>%
  group_by(score_bin) %>%
  summarize(
    bad_rate = mean(bad),
    total = n(),
    liczba_bad = sum(bad)
  ) -> goodrates_bins

# Wyświetlenie wyników
print(goodrates_bins)

```


```{r}
# Oblicz zakres punktacji
min_score <- floor(min(iv_data_with_scores_all$score))
max_score <- max(iv_data_with_scores_all$score)

# Budujemy breaks co 20 punktów, ostatni punkt to dokładnie max(score)
breaks_seq <- c(seq(min_score, max_score, by = 20), max_score)

# Usuwamy ewentualny duplikat ostatniego punktu
breaks_seq <- unique(breaks_seq)

# Tworzymy przedziały
library(dplyr)

iv_data_with_scores_all %>%
  mutate(score_bin = cut(score, breaks = breaks_seq, right = TRUE, include.lowest = TRUE)) %>%
  group_by(score_bin) %>%
  summarize(
    bad_rate = mean(bad),
    total = n(),
    liczba_bad = sum(bad)
  ) -> badrates_bins

```


#Wykres good(bad) rate w zależności od przedziałów score
```{r}
library(ggplot2)

ggplot(goodrates_bins, aes(x = score_bin, y = bad_rate, group = 1)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "darkblue", size = 2) +
  labs(
    title = "Bad rate względem przedziałów score",
    x = "Przedział score",
    y = "Bad rate"
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = seq(0, 1, 0.2)
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```


```{r}
# Załadowanie potrzebnych pakietów
library(pROC)
library(ggplot2)

# Tworzenie krzywej ROC
roc_obj <- roc(iv_data_with_scores_all$bad, -iv_data_with_scores_all$score)
auc_value <- auc(roc_obj)
gini_value <- 2*auc_value - 1

# Podstawowe informacje o krzywej ROC
cat(sprintf("AUC: %.4f\n", auc_value))
cat(sprintf("Gini: %.4f\n", gini_value))

# Wizualizacja krzywej ROC
roc_data <- data.frame(
  specificity = roc_obj$specificities,
  sensitivity = roc_obj$sensitivities
)

# Tworzenie wykresu
ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(color = "blue", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
  labs(
    title = "Krzywa ROC dla modelu scoringowego",
    subtitle = sprintf("AUC = %.4f, Gini = %.4f", auc_value, gini_value),
    x = "1 - Swoistość", # Polska nazwa dla 1-Specificity
    y = "Czułość"        # Polska nazwa dla Sensitivity
  ) +
  theme_minimal() +
  coord_equal() +
  annotate("text", x = 0.75, y = 0.25, 
           label = sprintf("AUC = %.4f\nGini = %.4f", auc_value, gini_value), 
           hjust = 0, size = 4) +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 10),
    axis.title = element_text(size = 10),
    panel.grid.minor = element_blank()
  )
```

```{r}
library(dplyr)

# Definiujemy wartości progowe score
thresholds <- c(0,100,200,300, 400, 500, 508)

# Tworzymy tabelę progową
#u nas bad to de facto good
threshold_table <- data.frame(score = thresholds) %>%
  rowwise() %>%
  mutate(
    rzeczywisty_bad = sum(iv_data_with_scores_all$bad[iv_data_with_scores_all$score <= score], na.rm = TRUE),
    przewidywany_bad = sum(iv_data_with_scores_all$score <= score, na.rm = TRUE)

  ) %>%
  ungroup()

# Wyświetlenie wyniku
print(threshold_table)

```